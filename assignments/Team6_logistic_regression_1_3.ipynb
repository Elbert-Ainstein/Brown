{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-brunei",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (Forbidden)."
     ]
    }
   ],
   "source": [
    "\n",
    "# # Credit Card Application\n",
    "\n",
    "# To create a model that forecasts the propensity (probability) of customers responding to a personal loan campaign, we will utilize logistic regression. The outcomes will be categorized and the factors influencing the answer will be found using the model's probability. Building a model that identifies clients who are most likely to accept the loan offer in upcoming personal loan campaigns is the objective.\n",
    "\n",
    "# ### 1) Importing required libraries\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "import itertools\n",
    "import subprocess\n",
    "from time import time\n",
    "from scipy import stats\n",
    "import scipy.optimize as opt  \n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ### 2) Importing and Descriptive Stats\n",
    "# \n",
    "# To market their loan products to people who already have deposit accounts, BankABC wants to create a direct marketing channel. To cross-sell personal loans to its current clients, the bank ran a test campaign. An enticing personal loan offer and processing charge waiver were aimed at a random group of 20000 clients. The targeted clients' information has been provided, together with information on how they responded to the marketing offer.\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# READ DATA\n",
    "data = pd.read_excel(\"Approval.xlsx\") \n",
    "data.shape  \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]:\n",
    "\n",
    "\n",
    "# GETTING THE DIMENSIONS OF THE ARRAY\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[4]:\n",
    "\n",
    "\n",
    "# VERIFYING IF WE IMPORTED THE RIGHT DATASET BY CHECKING THE FIRST XXX ENTRIES OF THE DATA\n",
    "data.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[5]:\n",
    "\n",
    "\n",
    "# VERIFYING IF WE IMPORTED THE RIGHT DATASET BY CHECKING THE LAST FIVE ENTRIES OF THE DATA\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]:\n",
    "\n",
    "\n",
    "# DESCRIPTIVE STATS\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "\n",
    "\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3) Handling Missing Values\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "#checking for null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[9]:\n",
    "\n",
    "\n",
    "#IMPUTE MISSING VALUES\n",
    "# For non numeric data using mode\n",
    "for val in data:\n",
    "    # Check if the column is of object type\n",
    "    if data[val].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        data = data.fillna(data[val].value_counts().index[0])\n",
    "        \n",
    "#for numeric data using mean\n",
    "for val in data:\n",
    "    # Check if the column is of numeric type (integer or floating-point)\n",
    "    if data[val].dtypes in [np.int64, np.float64]:\n",
    "        # Find the mean value\n",
    "        mean_value = data[val].mean()\n",
    "        # Replace missing values with the mean\n",
    "        data[val].fillna(mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[10]:\n",
    "\n",
    "\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[11]:\n",
    "\n",
    "\n",
    "#Converting all non-numeric data to numeric - using one hot encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Instantiate LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for val in data:\n",
    "    # Compare if the dtype is object\n",
    "    if data[val].dtypes=='object':\n",
    "        data[val]=le.fit_transform(data[val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[12]:\n",
    "\n",
    "\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[13]:\n",
    "\n",
    "\n",
    "# PLOTTING HISTOGRAMS FOR ALL VARIABLES\n",
    "\n",
    "fig, axes = plt.subplots(nrows=6, ncols=3, figsize=(18, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, val in enumerate(data.columns):\n",
    "    if data[val].dtypes in [np.int64, np.float64]:\n",
    "        data[val].hist(ax=axes[i], bins=30)\n",
    "        axes[i].set_title(val)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[14]:\n",
    "\n",
    "\n",
    "# CREATING A COPY TO RETAIN THE NUMERICAL INFORMATION OF THE DATA AS WE CHANGE THE 0 AND 1 TO\n",
    "# 'DID NOT RESPOND' AND 'RESPONDED'\n",
    "\n",
    "###\n",
    "data1 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[15]:\n",
    "\n",
    "\n",
    "# RENAMING THE 0 AND 1 TO\n",
    "# 'DID NOT RESPOND' AND 'RESPONDED' RESPECTIVELY\n",
    "#data1.loc[:, 'admitted'] = data.loc[:, 'admitted'].apply(lambda x: 'admitted' if x == 1 else 'not admitted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[16]:\n",
    "\n",
    "\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[17]:\n",
    "\n",
    "\n",
    "# # calculate the correlation matrix\n",
    "corr = data.corr()\n",
    "\n",
    "# plot the heatmap\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "sns.heatmap(corr, \n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "            linewidths=.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[18]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = data.drop(['DriversLicense','ZipCode'], axis=1)\n",
    "data = data.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[19]:\n",
    "\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "X,y = data[:,0:13] , data[:,13]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[20]:\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[21]:\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit model to the train set\n",
    "logreg.fit(rescaledX_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[22]:\n",
    "\n",
    "\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
    "random_state=None, solver='warn', tol=0.0001, verbose=0,warm_start=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[23]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test, y_test))\n",
    "\n",
    "# Print the confusion matrix of the logreg model\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[24]:\n",
    "\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "probs = logreg.predict_proba(X_test)\n",
    "preds = probs[:,1]\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.formula.api as sm \n",
    "import statsmodels.api as sma \n",
    "\n",
    "data = pd.read_excel(\"Approval.xlsx\") \n",
    "data['Debt'].fillna(data['Debt'].mean(), inplace=True)\n",
    "\n",
    "# glm stands for Generalized Linear Model\n",
    "mylogit = sm.glm(formula = \"Approved ~ Debt\", data = data, family = sma.families.Binomial()).fit() \n",
    "\n",
    "mylogit.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-universal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
